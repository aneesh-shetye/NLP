{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq_2_seq_with_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpkd8kC5tMpjzPVkhRxV8q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneesh-shetye/NLP/blob/master/seq_2_seq_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AqU4P0ubP6Q"
      },
      "source": [
        "installing the required versions of libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1wsgp3zbHmb",
        "outputId": "319c3eee-1d4b-40ca-c254-10b2b22477db"
      },
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 23.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 30.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 25.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 22.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 21.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzFv4OirbghN",
        "outputId": "7e9ea0d6-4a86-4624-b23d-f5ee0bcdcc67"
      },
      "source": [
        "!python -m spacy download de\n",
        "!python -m spacy download en "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 18.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (54.2.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp37-none-any.whl size=14907057 sha256=b63ff178d8557a49e86795169b6c429f692fd5de470f037d5b3fc8338b6418ef\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qgrmrtui/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.2.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUAiIx_fbmrv"
      },
      "source": [
        "import torch\n",
        "import  torchtext\n",
        "from torchtext.data.utils import  get_tokenizer\n",
        "from torchtext.vocab import Vocab \n",
        "import torch.nn as nn\n",
        "import numpy as np \n",
        "import spacy \n",
        "import random \n",
        "from torchtext.datasets import TranslationDataset, Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "from torch import Tensor "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3jA8TpFcxhD",
        "outputId": "1e363aa5-7f67-4451-f6ea-60a27b56c1f6"
      },
      "source": [
        "en_tokenizer = torch.device('cpu')\n",
        "\n",
        "if torch.cuda.is_available(): \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"You are using \", torch.cuda.get_device_name())\n",
        "else: \n",
        "    print(\"You are using cpu\")\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are using  Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oItYAyWye9cE"
      },
      "source": [
        "#defing tokenizer: the things that split your sentence into words or subwords\n",
        "en_tokenizer = get_tokenizer('spacy', language='en')\n",
        "de_tokenizer = get_tokenizer('spacy', language='de')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PZrCBheeit3",
        "outputId": "9e161f02-8ff2-4bfb-8df3-bd8903cb67c1"
      },
      "source": [
        "src_field = Field(init_token = '<src_sos>', eos_token='<src_eos>', lower= True, tokenize= de_tokenizer)\n",
        "trg_field = Field(init_token = '<trg_sos>', eos_token = '<trg_eos>', lower=True, tokenize=en_tokenizer)\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(src_field, trg_field))\n",
        "\n",
        "#making the vocabulary : \n",
        "\n",
        "src_field.build_vocab(train_data, min_freq =2) # replaces words which appear less than twice with <unk> token\n",
        "trg_field.build_vocab(train_data, min_freq=2)\n",
        "\n",
        "print(\"Source vocab size is :\", len(src_field.vocab))\n",
        "print(\"Target vocab size is : \", len(trg_field.vocab))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 1.04MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 278kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 264kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Source vocab size is : 7855\n",
            "Target vocab size is :  5893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQhGnZW8gvMV"
      },
      "source": [
        "making train and test iterators: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgEL_TjpgcGc"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator = torchtext.data.BucketIterator(train_data, batch_size=BATCH_SIZE, device=device)\n",
        "test_iterator = torchtext.data.BucketIterator(test_data, batch_size=BATCH_SIZE, device=device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BDfby8thg4S"
      },
      "source": [
        "\"\"\"\n",
        "defining the encoder: \n",
        "\n",
        "    input : src_sentence\n",
        "    output : hidden_states + \n",
        "             final hidden states (encoding)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Encoder_RNN(nn.Module): \n",
        "    \n",
        "    def __init__(self, \n",
        "                 src_dim : int, \n",
        "                 no_features_enc: int, \n",
        "                 hidden_size: int, \n",
        "                 no_layers_enc: int,\n",
        "                 dropout: float = 0.5): \n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(src_dim , no_features_enc)\n",
        "        self.recurrent = nn.GRU(no_features_enc, hidden_size, bidirectional=True, num_layers = no_layers_enc) \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(hidden_size*2, hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, \n",
        "                src: Tensor)-> tuple : \n",
        "\n",
        "                #src.shape = [seq_len, batch_size]\n",
        "                src = src.to(device)\n",
        "\n",
        "                embeddings = self.dropout(self.embed(src))\n",
        "                #embeddings.shape = [seq_len, batch_size, no_features_enc]\n",
        "\n",
        "                h, h_n = self.recurrent(embeddings) #h_n.shape  [num_layers*2, batch_size, hidden_size ]\n",
        "\n",
        "                h_n = torch.cat((h_n[-2, : , : ], h_n[-1, : , :]), dim=1) # given in the paper that we conccatenate the forward and backward states\n",
        "\n",
        "                #h_n.shape = [batch_size, hidden_size*2]\n",
        "                #h.shape = [src_len, batch_size, hidden_size_enc*2]\n",
        "                \n",
        "                h_n = self.linear(h_n)\n",
        "                #h_n.shape = batch_size, dec_hidden_size\n",
        "\n",
        "                h_n = h_n.unsqueeze(0)\n",
        "                #h_n.shape = 1, batch_Size, dec_hidden_size\n",
        "                \n",
        "                return h, h_n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9rB1ODPsmL9"
      },
      "source": [
        "encoder = Encoder_RNN(src_dim=200, \n",
        "                      no_features_enc=100, \n",
        "                      hidden_size=200, \n",
        "                      no_layers_enc=3)\n",
        "encoder.to(device)\n",
        "a = torch.zeros([38, 64], dtype=torch.long)\n",
        "h, h_n = encoder(a)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo6FTJFc_tin"
      },
      "source": [
        "\"\"\" \n",
        "defining attention (as used to get the results in paper): \n",
        "\n",
        "    input : enc_hidden_states \n",
        "            dec_hidden_state\n",
        "    output : context vector \n",
        "\"\"\"\n",
        "\n",
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, \n",
        "                 hidden_size: int): \n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        #enc and dec hidden size are equal \n",
        "        self.linear_enc = nn.Linear(hidden_size*2, hidden_size, bias=False)\n",
        "        self.linear_dec = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "        self.linear_sum = nn.Linear(hidden_size,1, bias=False )\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "\n",
        "\n",
        "    def forward(self, \n",
        "                h: Tensor, \n",
        "                s_prev: Tensor)-> Tensor : \n",
        "\n",
        "        \n",
        "        #h.shape = src_len , batch_size, hidden_size*2\n",
        "        #s_prev.shape = batch_size, hidden_size \n",
        "\n",
        "        h, s_prev = h.to(device), s_prev.to(device)\n",
        "\n",
        "        h_2 = self.linear_enc(h) #h.shape = src_len, batch_size, hidden_size\n",
        "        s_prev = self.linear_dec(s_prev) #s_prev.shape = batch_size, hidden_size\n",
        "\n",
        "        sum = torch.tanh(h_2 + s_prev) #sum.sahpe = src_len, batch_size, hidden_size\n",
        "\n",
        "        a = self.linear_sum(sum) #a.shape = src_len, batch_size, 1\n",
        "\n",
        "        alpha = self.softmax(a)  #a.shape = src_len, batch_Size, 1\n",
        "\n",
        "        c = torch.mul(alpha, h) #c.shape = src_len, batch_size, hidden_size*2\n",
        "\n",
        "        c = torch.sum(c, 0) #c.shape = batch_size, hidden_size*2\n",
        "\n",
        "\n",
        "        return c\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0x0kQRMuvck"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "Decoder : \n",
        "    input: s_prev, \n",
        "            a,\n",
        "            prev_output \n",
        "\n",
        "    output: s, \n",
        "            output \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class Decoder_RNN(nn.Module): \n",
        "\n",
        "    def __init__(self, \n",
        "                 hidden_size: int, \n",
        "                 dropout:float, \n",
        "                 no_features_dec: int,\n",
        "                 output_dim: int): \n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(output_dim, no_features_dec)\n",
        "        self.recurrent = nn.GRU(no_features_dec + 2*hidden_size, hidden_size)\n",
        "        self.linear = nn.Linear(hidden_size, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, \n",
        "                prev_output: Tensor, \n",
        "                s_prev: Tensor, \n",
        "                c: Tensor)-> tuple : \n",
        "\n",
        "        # prev_output.shape - [1, batch_size]\n",
        "        #s_prev.shape = [1, batch_size, dec_hidden_size]\n",
        "        #c.shape = [batch_size, hidden_size*2]\n",
        "\n",
        "        prev_output, s_prev, c = prev_output.to(device), s_prev.to(device), c.to(device)\n",
        "\n",
        "        c = c.unsqueeze(0)\n",
        "\n",
        "        embeddings = self.dropout(self.embed(prev_output))\n",
        "        #embeddings.shape = [1, batch_size, no_features_dec]\n",
        "\n",
        "        embeddings = embeddings.unsqueeze(0)\n",
        "\n",
        "        output , s = self.recurrent(torch.cat((embeddings, c), dim=2), s_prev) \n",
        "        #output.shape = [1, batch_size, hidden_size]\n",
        "        #s.shape = [1, batch_size, hidden_size]\n",
        "\n",
        "        output = self.linear(output)\n",
        "        #output.shape = [1, batch_size, output_dim ]\n",
        "\n",
        "        return output, s\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBrr5B47KIby"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "Seq2Seq with attention model : \n",
        "    input : enc_hidden_states\n",
        "            prev_output,\n",
        "            s_prev\n",
        "    \n",
        "    output : output,  \n",
        "             s\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Seq_2_Seq_att(nn.Module): \n",
        "\n",
        "    def __init__(self, \n",
        "                 dec: nn.Module, \n",
        "                 att: nn.Module): \n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.dec = dec \n",
        "        self.att = att\n",
        "        \n",
        "    \n",
        "    def forward(self, \n",
        "                h: Tensor,\n",
        "                prev_out: Tensor, \n",
        "                s_prev: Tensor)-> tuple: \n",
        "\n",
        "        h, prev_out, s_prev = h.to(device), prev_out.to(device), s_prev.to(device)\n",
        "\n",
        "        # print(h.shape)\n",
        "        c = self.att(h, s_prev)\n",
        "        output, s = dec(prev_out, s_prev, c)\n",
        "\n",
        "        return output, s       \n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwl5XC-Hrtzz"
      },
      "source": [
        "\"\"\"\n",
        "training loop : \n",
        "tf = 0 for testing\n",
        "\"\"\"\n",
        "\n",
        "def train(iterator: torchtext.data.BucketIterator, \n",
        "          model: nn.Module,\n",
        "          enc: nn.Module,\n",
        "          criterion: nn.Module, \n",
        "          tf: float = 0.9):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    output_dim = len(trg_field.vocab)\n",
        "\n",
        "\n",
        "    for i, data in enumerate(iterator): \n",
        "\n",
        "        batch_loss = 0\n",
        "        data.src, data.trg = data.src.to(device), data.trg.to(device)\n",
        "\n",
        "        batch_size = data.trg.shape[1]\n",
        "\n",
        "        h, h_n = enc(data.src)\n",
        "        #h.shape = [src_len, batch_size, hidden_size*2]\n",
        "        #h_n.shape = [1, batch_size, hidden_size]\n",
        "\n",
        "        s_prev = h_n \n",
        "\n",
        "        prev_output = data.trg[0].to(device) #prev_output.shape = [1, batch_size]\n",
        "\n",
        "        predictions = torch.zeros(1, prev_output.shape[0], len(trg_field.vocab) )\n",
        "        predictions = predictions.to(device)\n",
        "        \n",
        "        target_sentence = []\n",
        "        predicted_sentence = []\n",
        "\n",
        "        epoch_loss = 0\n",
        "        e = 0 \n",
        "        for trg_id in range(1, data.trg.shape[0]):  \n",
        "\n",
        "            output, s = model(h, prev_output, s_prev)\n",
        "            #output.shape = [1, batch_size, output_dim ]\n",
        "            #s.shape  = [1, batch_size, hidden_size]\n",
        "\n",
        "            output = output.to(device)\n",
        "            s_prev = s.to(device)\n",
        "\n",
        "            predictions = torch.cat((predictions, output))\n",
        "\n",
        "            target = data.trg[trg_id]\n",
        "\n",
        "            if i%100 == 0 : \n",
        "\n",
        "                target_sentence.append(target[0].item())\n",
        "\n",
        "            prob = [True, False][random.random() < tf]  #probability of taking the actual target \n",
        "\n",
        "            if prob : \n",
        "\n",
        "                prev_output = target\n",
        "\n",
        "            else: \n",
        "\n",
        "                prev_output = torch.argmax(nn.Softmax(dim=-1)(output.squeeze(0)), dim=1)\n",
        "\n",
        "                prev_output = prev_output.to(device)\n",
        "\n",
        "            if i%100 == 0 : \n",
        "\n",
        "                predicted_sentence.append(nn.Softmax(dim=-1)(output[:, 0, :]).argmax().item())\n",
        "\n",
        "        if i%100 == 0 : \n",
        "\n",
        "            print(\"target:\")\n",
        "\n",
        "            for word in  target_sentence: \n",
        "                print(trg_field.vocab.itos[word], end = \" \" ) \n",
        "\n",
        "            print(\"\")\n",
        "\n",
        "            print(\"output\")\n",
        "\n",
        "            for word in predicted_sentence : \n",
        "\n",
        "                print(trg_field.vocab.itos[word], end = \" \")\n",
        "\n",
        "            print(\" \")\n",
        "\n",
        "\n",
        "        target_ = data.trg[1: ].clone().to(device)\n",
        "\n",
        "        target_  = target_.view([-1])\n",
        "\n",
        "        target_ = list(target_)\n",
        "\n",
        "        target_ = torch.LongTensor(target_).to(device)\n",
        "\n",
        "        predictions = predictions[1: ]\n",
        "\n",
        "        batch_loss = criterion(predictions.view([-1, output_dim]), target_)\n",
        "\n",
        "        if i%100 == 0: \n",
        "\n",
        "            print(\"Batch_loss (batch)\", i, \"=\", batch_loss)\n",
        "\n",
        "\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += batch_loss\n",
        "        e += 1\n",
        "        \n",
        "        \n",
        "    return e, epoch_loss \n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i06c0H-Ab4nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13579e6f-9e09-48e8-aa69-b1d83869f614"
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.zeros([1, 2, 5])\n",
        "torch.nn.Softmax(dim=-1)(a.squeeze(0))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLIxLWiIezOu",
        "outputId": "c1ee9b6f-7739-42f7-a717-668da42f01b9"
      },
      "source": [
        "len(src_field.vocab)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5hVLfYwVGEU",
        "outputId": "e0d30875-be62-4c96-8f42-a36e2bb02fcf"
      },
      "source": [
        "\n",
        "hidden_size = 300\n",
        "\n",
        "\n",
        "enc = Encoder_RNN(src_dim = len(src_field.vocab) , \n",
        "                  no_features_enc = 150, \n",
        "                  hidden_size = hidden_size,\n",
        "                  no_layers_enc= 2,\n",
        "                  dropout=0.5)\n",
        "\n",
        "dec = Decoder_RNN(hidden_size=hidden_size,\n",
        "                  dropout = 0.5, \n",
        "                  no_features_dec=150, \n",
        "                  output_dim= len(trg_field.vocab))\n",
        "\n",
        "enc.to(device)\n",
        "dec.to(device)\n",
        "\n",
        "att = Attention(hidden_size = hidden_size)\n",
        "\n",
        "att.to(device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Attention(\n",
              "  (linear_enc): Linear(in_features=600, out_features=300, bias=False)\n",
              "  (linear_dec): Linear(in_features=300, out_features=300, bias=False)\n",
              "  (linear_sum): Linear(in_features=300, out_features=1, bias=False)\n",
              "  (softmax): Softmax(dim=0)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M6nOikjf43R",
        "outputId": "a7a142c4-bc1c-48f0-8ffa-c3b8e3540757"
      },
      "source": [
        "model = Seq_2_Seq_att(dec= dec, \n",
        "                      att= att)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq_2_Seq_att(\n",
              "  (dec): Decoder_RNN(\n",
              "    (embed): Embedding(5893, 150)\n",
              "    (recurrent): GRU(750, 300)\n",
              "    (linear): Linear(in_features=300, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (att): Attention(\n",
              "    (linear_enc): Linear(in_features=600, out_features=300, bias=False)\n",
              "    (linear_dec): Linear(in_features=300, out_features=300, bias=False)\n",
              "    (linear_sum): Linear(in_features=300, out_features=1, bias=False)\n",
              "    (softmax): Softmax(dim=0)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqky_emLgeQL",
        "outputId": "5564f721-039c-4d7c-d163-857e7ba48514"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(enc)+count_parameters(model)} trainable parameters')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 7670593 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5krM4eJhjhj"
      },
      "source": [
        "PAD_IDX = trg_field.vocab[\"<pad>\"]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index= PAD_IDX)\n",
        "\n",
        "learning_rate = 0.00001\n",
        "\n",
        "optimizer = torch.optim.Adam([{\"params\": model.parameters()}, \n",
        "                              {\"params\": enc.parameters()}], lr = learning_rate)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80ih4OdDhUV1",
        "outputId": "ecb55ad4-ca5c-4775-a894-2239c412bc79"
      },
      "source": [
        "EPOCH = 10\n",
        "for e in range(EPOCH):\n",
        "\n",
        "    iters , loss =  train(iterator=train_iterator, \n",
        "                  model=model, \n",
        "                  enc = enc, \n",
        "                  criterion=criterion, \n",
        "                tf = 0.75)\n",
        "    \n",
        "    print(\"EPOCH LOSS for epoch\", e, \"=\", loss/iters)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target:\n",
            "a man doing a trick on his bmx bike on top of a half pipe <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man is a a a a a a a <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 0 = tensor(4.9415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a teenage boy wearing a blue and white uniform playing a form of hockey . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man is is a a a a . <trg_eos> . <trg_eos> . . <trg_eos> . <trg_eos> . <trg_eos> . . <trg_eos> . <trg_eos> . <trg_eos>  \n",
            "Batch_loss (batch) 100 = tensor(5.0380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a black dog is chasing another black dog that 's carrying a ball in its mouth . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a a a a a . . . . . . . <trg_eos> . . . . . . . . . <trg_eos> . .  \n",
            "Batch_loss (batch) 200 = tensor(5.1036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "EPOCH LOSS for epoch 0 = tensor(5.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "target:\n",
            "a man in a blue shirt and a woman in a pink skirt sit around other people in the background . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a a a a a a a a a . . . . . . . <trg_eos> . . . . . .  \n",
            "Batch_loss (batch) 0 = tensor(5.0646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a black dog jumping off a riverbank near a wooded area . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a a . . . <trg_eos> . . <trg_eos> . . <trg_eos> . <trg_eos> . <trg_eos> . . <trg_eos> . . <trg_eos> . <trg_eos> .  \n",
            "Batch_loss (batch) 100 = tensor(5.1162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a boy in a life jacket jumps onto something yellow , out of frame . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a <trg_eos> <trg_eos> <trg_eos> . <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 200 = tensor(5.1226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "EPOCH LOSS for epoch 1 = tensor(5.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "target:\n",
            "a closeup of a man shooting a handgun into the woods . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 0 = tensor(5.1747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a man is playing the keyboard and singing into a microphone while a young boy watches . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man is a a a a a a a a a a a a a a a a <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 100 = tensor(5.2019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "two <unk> are making their way through woods . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man is a a a a <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 200 = tensor(5.0651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "EPOCH LOSS for epoch 2 = tensor(5.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "target:\n",
            "a girl holds onto a rope above the water . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a a a <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 0 = tensor(5.0497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a woman wearing pink sweatshirt cutting cheese with knife . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a a a . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> .  \n",
            "Batch_loss (batch) 100 = tensor(5.0404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a cowboy with a white hat <unk> to wrangle a calf at a rodeo . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a a a a a a a a . <trg_eos> <trg_eos> . <trg_eos> . . <trg_eos> . <trg_eos> . . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos>  \n",
            "Batch_loss (batch) 200 = tensor(5.0825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "EPOCH LOSS for epoch 3 = tensor(5.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "target:\n",
            "a jack <unk> terrier is <unk> for distance jumping as he tries to catch a frisbee . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "two young in a a a a a a <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 0 = tensor(5.1870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a man is selling decals on the street . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos>  \n",
            "Batch_loss (batch) 100 = tensor(5.0137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "two women jogging down the street . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a . <trg_eos> . <trg_eos> . <trg_eos> . . <trg_eos> . . <trg_eos> . <trg_eos> . . <trg_eos> . . <trg_eos> . <trg_eos> . .  \n",
            "Batch_loss (batch) 200 = tensor(5.1284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "EPOCH LOSS for epoch 4 = tensor(5.0271, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "target:\n",
            "the young girl is rollerblading outside near green bushes . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a are in a a a a . <trg_eos> . <trg_eos> . . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . . <trg_eos> . . . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . . <trg_eos> .  \n",
            "Batch_loss (batch) 0 = tensor(5.1696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a child wearing a coat among some trees and funny designs . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a a a a a a a <trg_eos> . <trg_eos> . <trg_eos> . . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . .  \n",
            "Batch_loss (batch) 100 = tensor(5.0635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "brown dog with mouth open standing amidst greenery . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "two man is a a a . <trg_eos> . <trg_eos> <trg_eos> . <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> . <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> . <trg_eos> <trg_eos> . <trg_eos> <trg_eos> <trg_eos> .  \n",
            "Batch_loss (batch) 200 = tensor(5.1215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "EPOCH LOSS for epoch 5 = tensor(5.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "target:\n",
            "a man in a black shirt sits next to an old woman in a pink shirt on a train . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a . <trg_eos> . . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . . <trg_eos> . <trg_eos> . . <trg_eos> . <trg_eos> . .  \n",
            "Batch_loss (batch) 0 = tensor(5.1272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a little boy in a <unk> sweatshirt tries to catch a green balloon above him . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a a a a a a a a . a . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> .  \n",
            "Batch_loss (batch) 100 = tensor(5.0652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a baby in a yellow shirt smiles . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a a a a . <trg_eos> . . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> .  \n",
            "Batch_loss (batch) 200 = tensor(5.1456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "EPOCH LOSS for epoch 6 = tensor(5.1494, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "target:\n",
            "an asian woman is in a rice paddy with packing boxes . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man in a a a a a . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . . . . <trg_eos> . <trg_eos> . <trg_eos>  \n",
            "Batch_loss (batch) 0 = tensor(5.2053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "two dogs are facing each other in a grassy field . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "two men and a <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 100 = tensor(5.1712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a woman in an apron is holding a fish and there is a blue pot and several other ingredients on the table . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man is a a a a <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 200 = tensor(5.0269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "EPOCH LOSS for epoch 7 = tensor(5.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "target:\n",
            "a woman it talking on the phone behind a rack with the big blue plastic bottles . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man is a a a a a <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 0 = tensor(5.0598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "two young mothers are visiting at the dining room table while keeping an eye on their youngsters . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a woman in a a a a a a a a a a a a a a a <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 100 = tensor(5.2290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "someone wearing shorts and a t - shirt jumping over white chairs . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "two people in a a a a a a a <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos> <trg_eos>  \n",
            "Batch_loss (batch) 200 = tensor(5.0260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "EPOCH LOSS for epoch 8 = tensor(5.0423, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "target:\n",
            "a police officer leans against his motorcycle and watches the streets . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a woman is a a a a a a a a a a a a a a a a a a a a a  \n",
            "Batch_loss (batch) 0 = tensor(5.1473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "a blond - haired boy is looking at an odd looking <unk> robot . <trg_eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a man is a a . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . . <trg_eos> . <trg_eos> . <trg_eos> . <trg_eos> . . <trg_eos> .  \n",
            "Batch_loss (batch) 100 = tensor(5.0775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "target:\n",
            "this person is laying on the floor at the bottom of the stairs and is missing a shoe . <trg_eos> <pad> <pad> <pad> <pad> \n",
            "output\n",
            "a people in a . . <trg_eos> . <trg_eos> . . <trg_eos> . . <trg_eos> . . . <trg_eos> . . <trg_eos> . .  \n",
            "Batch_loss (batch) 200 = tensor(5.1231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "EPOCH LOSS for epoch 9 = tensor(5.1182, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wneHf0UMjOim"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}