{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "char_rnn_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPhsvXMALLwxu3ZpgsbmEO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneesh-shetye/NLP/blob/master/char_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW5bORROOjJg",
        "outputId": "789ef783-8de8-4bd4-eeda-830fcf935294"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import random\n",
        "\n",
        "device = torch.device(type='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c23ysQNrOmMc",
        "outputId": "b9d484fb-15d0-4a1f-f866-341d1f50a5da"
      },
      "source": [
        "data = open('dino_names.txt', 'r').read() \n",
        "data = data.lower()\n",
        "data = data.replace(\"\\n\", \".\")\n",
        "chars = list(set(data))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "\n",
        "print(\"no of data = \" ,data_size)\n",
        "print(\"no of unique chars = \" ,vocab_size)\n",
        "\n",
        "char_to_ix = {ch:i for i,ch in enumerate(chars)}   \n",
        "ix_to_char = {i:ch for i,ch in enumerate(chars)}    \n",
        "\n",
        "data = data.replace(\".\", \" \")\n",
        "data = data.split()\n",
        "random.shuffle(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no of data =  19914\n",
            "no of unique chars =  28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-dFtQxTO3hw"
      },
      "source": [
        "class rnn(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(rnn, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size \n",
        "        self.output_size = input_size # its a predective char rnn\n",
        "\n",
        "        self.e2i = nn.Linear(input_size, input_size)\n",
        "        self.i2h = nn.Linear(hidden_size + input_size, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, self.output_size)\n",
        "        self.o2o = nn.Linear(self.output_size, self.output_size)\n",
        "        self.tanh = nn.Tanh()\n",
        "        #self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "\n",
        "        input = self.e2i(input)\n",
        "        input_hidd = torch.cat((input,hidden), dim=1)\n",
        "        hidden = self.i2h(input_hidd)\n",
        "        hidden = self.tanh(hidden)\n",
        "        output = self.h2o(hidden)\n",
        "        output = self.o2o(output)\n",
        "        #output = self.softmax(output)\n",
        "\n",
        "        return hidden , output "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7l3WtV-O5me"
      },
      "source": [
        "learning_rate = 0.0005\n",
        "\n",
        "model = rnn(input_size=vocab_size, hidden_size=75)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzuZKnHeO7eT"
      },
      "source": [
        "def train(data, hidden_size, vocab_size):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    no = 0\n",
        "    for word in data:\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        chars_in_data = list(word)\n",
        "        length_of_word = len(chars_in_data)\n",
        "\n",
        "        hidden = torch.zeros([1, hidden_size])\n",
        "        hidden = hidden.to(device)\n",
        "\n",
        "        predictions = torch.zeros([1,vocab_size])\n",
        "        predictions[0,char_to_ix[chars_in_data[0]]] = 1\n",
        "        predictions = predictions.to(device)\n",
        "\n",
        "        target = [char_to_ix[i]  for i in chars_in_data]\n",
        "        target.append(char_to_ix[\".\"]) \n",
        "        target_tensor = torch.LongTensor(target)\n",
        "\n",
        "        for char in chars_in_data:\n",
        "            \n",
        "            input_idx = char_to_ix[char]\n",
        "            input = torch.zeros([1, vocab_size], dtype=torch.float)\n",
        "            input = input.to(device)\n",
        "            input[0, input_idx] = 1\n",
        "\n",
        "            hidden, output = model(input, hidden)\n",
        "\n",
        "            predictions = torch.cat((predictions, output), dim=0)\n",
        "            predictions = predictions.to(device)\n",
        "            \n",
        "\n",
        "\n",
        "        batch_loss = criterion(predictions, target_tensor)\n",
        "        no+=1\n",
        "        total_loss += batch_loss\n",
        "        epoch_loss+= batch_loss \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "    \n",
        "    epoch_loss = epoch_loss/no\n",
        "\n",
        "    print(epoch_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eud0n3OnSA86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1227a0ac-99c6-4701-9d34-57cc5c28368b"
      },
      "source": [
        "for _ in range(15):\n",
        "    train(data=data, hidden_size=75, vocab_size=vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2810, grad_fn=<DivBackward0>)\n",
            "tensor(1.9582, grad_fn=<DivBackward0>)\n",
            "tensor(1.8863, grad_fn=<DivBackward0>)\n",
            "tensor(1.8387, grad_fn=<DivBackward0>)\n",
            "tensor(1.7996, grad_fn=<DivBackward0>)\n",
            "tensor(1.7642, grad_fn=<DivBackward0>)\n",
            "tensor(1.7346, grad_fn=<DivBackward0>)\n",
            "tensor(1.7097, grad_fn=<DivBackward0>)\n",
            "tensor(1.6877, grad_fn=<DivBackward0>)\n",
            "tensor(1.6677, grad_fn=<DivBackward0>)\n",
            "tensor(1.6491, grad_fn=<DivBackward0>)\n",
            "tensor(1.6315, grad_fn=<DivBackward0>)\n",
            "tensor(1.6148, grad_fn=<DivBackward0>)\n",
            "tensor(1.5992, grad_fn=<DivBackward0>)\n",
            "tensor(1.5845, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dkHTLIWSwih",
        "outputId": "9991499e-8e02-4edb-c593-e12f42de5dae"
      },
      "source": [
        "char_to_ix[\".\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0BHTL_pmOeO",
        "outputId": "bf1a8c8d-5245-4274-b56f-0314c63ea3ee"
      },
      "source": [
        "\n",
        "model.eval()\n",
        "hidden_size = 75\n",
        "\n",
        "for letters in chars:\n",
        "\n",
        "    print(letters,\":\", end = \" \")\n",
        "    print(letters, end=\"\")\n",
        "    char = letters\n",
        "    input_idx = char_to_ix[char]\n",
        "    input = torch.zeros([1, vocab_size], dtype=torch.float)\n",
        "    input = input.to(device)\n",
        "    input[0, input_idx] = 1\n",
        "\n",
        "    hidden = torch.zeros([1, hidden_size])\n",
        "    hidden = hidden.to(device)\n",
        "    idx = torch.tensor(char_to_ix[letters])\n",
        "\n",
        "    while ix_to_char[idx.item()] != \".\":\n",
        "        \n",
        "        hidden, output = model(input, hidden)\n",
        "        \n",
        "        output = nn.Softmax(dim=1)(output)\n",
        "        idx = output.argmax()\n",
        "        input = torch.zeros([1, vocab_size], dtype=torch.float)\n",
        "        input[0, idx] = 1\n",
        "        print(ix_to_char[idx.item()], end=\"\")\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m : manganosaurus.\n",
            "\n",
            "x : xiangosaurus.\n",
            "\n",
            "n : notosaurus.\n",
            "\n",
            "k : kararosaurus.\n",
            "\n",
            "l : langanosaurus.\n",
            "\n",
            "s : saurosaurus.\n",
            "\n",
            "u : urophosaurus.\n",
            "\n",
            "a : altarosaurus.\n",
            "\n",
            "p : palarosaurus.\n",
            "\n",
            "o : ornithosaurus.\n",
            "\n",
            "y : yunganosaurus.\n",
            "\n",
            "i : inosaurus.\n",
            "\n",
            "h : harahosaurus.\n",
            "\n",
            "v : varasaurus.\n",
            "\n",
            "z : zenganosaurus.\n",
            "\n",
            "t : taratosaurus.\n",
            "\n",
            "w : walahosaurus.\n",
            "\n",
            "j : jiangosaurus.\n",
            "\n",
            ". : .\n",
            "\n",
            "g : gonganosaurus.\n",
            "\n",
            "c : chengosaurus.\n",
            "\n",
            "f : furopelta.\n",
            "\n",
            "b : baratosaurus.\n",
            "\n",
            "  :  angangosaurus.\n",
            "\n",
            "r : rarosaurus.\n",
            "\n",
            "d : danganosaurus.\n",
            "\n",
            "q : quangosaurus.\n",
            "\n",
            "e : eratosaurus.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW2BN3D9Wgiv"
      },
      "source": [
        "Using Preprovided RNN, LSTM and GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4x2BLLIayZu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}